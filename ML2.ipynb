{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpAp2rbCGcV0",
        "outputId": "9138967b-f5a5-41a0-d7ca-94c38a7e811b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5013 - accuracy: 0.8265\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3796 - accuracy: 0.8621\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3388 - accuracy: 0.8773\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3163 - accuracy: 0.8842\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2960 - accuracy: 0.8913\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2815 - accuracy: 0.8962\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2685 - accuracy: 0.8996\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2572 - accuracy: 0.9035\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2501 - accuracy: 0.9072\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2396 - accuracy: 0.9102\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2306 - accuracy: 0.9131\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.9161\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2181 - accuracy: 0.9183\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2105 - accuracy: 0.9221\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2052 - accuracy: 0.9240\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1985 - accuracy: 0.9254\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1958 - accuracy: 0.9265\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1875 - accuracy: 0.9301\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1825 - accuracy: 0.9320\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1790 - accuracy: 0.9327\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1770 - accuracy: 0.9341\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1679 - accuracy: 0.9368\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1663 - accuracy: 0.9378\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1626 - accuracy: 0.9395\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1587 - accuracy: 0.9398\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1553 - accuracy: 0.9416\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1527 - accuracy: 0.9426\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1486 - accuracy: 0.9445\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1443 - accuracy: 0.9459\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1431 - accuracy: 0.9457\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1381 - accuracy: 0.9483\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1352 - accuracy: 0.9480\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1347 - accuracy: 0.9487\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9514\n",
            "Reached 95% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1300 - accuracy: 0.9514\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c965d4d7d90>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a new class called myCallback ; that takes tf.keras.callbacks.Callback as a parameter.\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  # In it we define the on_epoch_end function, which will give us details about logs for this epoch\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    # In this logs is an accuracy value,so al we have to do is see if it is greater then 0.95\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      # if it is ,we can stop training by saying self.model.stop_training = True\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "# We create a callbacks object to be an instance of the myCallback function\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images,training_labels,epochs=50,callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdkJbi9ugD4b",
        "outputId": "229ede66-57fa-47ac-fcec-ed33c02c5d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "[0.09227053 0.00436802 0.07333893 0.01865848 0.01880622 0.0938476\n",
            " 0.31737378 0.07837792 0.29595333 0.00700525]\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# The model has been trained\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
